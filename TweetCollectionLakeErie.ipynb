{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Tweets using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tweepy as tw #make sure to install v3.10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# install preprocessor using pip install via Command Prompt/Anaconda prompt: pip install tweet-preprocessor\n",
    "from preprocessor import api as p\n",
    "#from preprocessor.api import clean, tokenize, parse #to clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "access_token = \"1311658729201377281-alEuRquK89jGbga7ckTsFhIlkRVPOY\"\n",
    "access_token_secret = \"rpQowQaio69m3XMByxXEzUdo73WPnpaPuYTQpAFH9cjoa\"\n",
    "api_key = \"E0RK2oHynrMIJ9YVrvuhIIjc6\"\n",
    "api_key_secret = \"kHnfmtYn7J66MkR7bUE3BTnWsW64ZUDUIxtw9bThP5kmDjq0Vl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication app\n",
    "auth = tw.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year from: 2013\n",
      "Year to: 2020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-94f7ffecfae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Iterate through each object and get location, tweet, date, coordinates and place for each record\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# check if there is an 'extended_tweet' property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;31m# Reached end of current page, get the next page...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_token\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_cursors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36msearch_full_archive\u001b[1;34m(self, environment_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1303\u001b[0m                             \u001b[1;34m'next'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \"\"\"\n\u001b[1;32m-> 1305\u001b[1;33m         return bind_api(\n\u001b[0m\u001b[0;32m   1306\u001b[0m             \u001b[0mapi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/tweets/search/fullarchive/{}.json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[1;31m# Execute request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                     resp = self.session.request(self.method,\n\u001b[0m\u001b[0;32m    184\u001b[0m                                                 \u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                                                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[0;32m    363\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[0mkeyfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data)\u001b[0m\n\u001b[0;32m    384\u001b[0m     ) or IS_SECURETRANSPORT:\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         warnings.warn(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# ctx._wrap_socket()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         return self.sslsocket_class._create(\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1038\u001b[0m                         \u001b[1;31m# non-blocking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find by phrase or keywords within a specified time\n",
    "search_words = '\"lake erie\" has:links'\n",
    "#search_words = '\"lake erie\" -has:links' \n",
    "# we can not use -filter:links etc for premium API search\n",
    "# use this link instead https://developer.twitter.com/en/docs/twitter-api/premium/rules-and-filtering/using-premium-operators\n",
    "# it is equivalent to utah lake until:2020-12-20 since:2020-11-28 -filter:links\n",
    "# we can't filter out retweets in the premium search\n",
    "\n",
    "# advanced search in Twitter search box \n",
    "# utah lake (#utahlake) until:2020-12-03 since:2020-11-28 -filter:links -filter:retweets\n",
    "# If I include hashtag in search, it wouldn't show the ones without hashtag\n",
    "# May be we can have a separate search by #utahlake and then combine both the dataframes\n",
    "\n",
    "# From date, to date, for premium API search the date should be in format yyyyMMddHHmm\n",
    "year_from = int(input(\"Year from: \"))\n",
    "year_to = int(input(\"Year to: \"))\n",
    "date_since = f'{year_from}01010000' #from January 1st, 12:00AM UTC\n",
    "#date_until = f'{year_to}12312359' #to December 31st, 11:59PM UTC\n",
    "date_until = f'{year_to}12310300' #for 2020 3AM UTC\n",
    "\n",
    "#date_since = f'{year}12250000' #test\n",
    "#date_until = f'{year}12280000' #test\n",
    "\n",
    "# Create a cursor object that iterates over the requested information\n",
    "# had to create a dev environment named \"SentimentAnalysis\" in Twitter's Developer Portal\n",
    "tweets = tw.Cursor(api.search_full_archive, environment_name = \"SentimentAnalysis\",\n",
    "                   query=search_words,\n",
    "                   fromDate=date_since, toDate=date_until).items()\n",
    "\n",
    "# Parse the cursor object into rows of lists using list comprehension\n",
    "#rows = [[tweet.user.location, tweet.text, tweet.created_at, tweet.coordinates] for tweet in tweets]\n",
    "\n",
    "# Make a list to store each item return in a payload\n",
    "rows = []\n",
    "\n",
    "# Iterate through each object and get location, tweet, date, coordinates and place for each record\n",
    "for tweet in tweets:\n",
    "    \n",
    "    # check if there is an 'extended_tweet' property\n",
    "    if ('extended_tweet' in dir(tweet)) == True: \n",
    "        # if so, instead of 'text', get 'full_text'\n",
    "        row = [tweet.user.location, tweet.extended_tweet['full_text'], tweet.created_at, tweet.coordinates, tweet.retweeted, tweet.place]\n",
    "    else:\n",
    "        row = [tweet.user.location, tweet.text, tweet.created_at, tweet.coordinates, tweet.retweeted, tweet.place]\n",
    "\n",
    "    # Append each item to the list\n",
    "    rows.append(row)\n",
    "\n",
    "# Tweets starting with an RT mean that they are retweets \n",
    "\n",
    "# more on geo-referenced tweets: \n",
    "# https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/geo\n",
    "# if required, look into user.derived.locations.geo\n",
    "# it assigns lat/long based on user's profile and the geographic precision they set\n",
    "# for example, if a user set their precision at the country-level, it will show center of US at lat/long\n",
    "# so it is not too accurate and might be irrelevant to us\n",
    "# https://developer.twitter.com/en/docs/twitter-api/enterprise/enrichments/overview/profile-geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from the rows of lists\n",
    "df_tweet = pd.DataFrame(data=rows, columns=['location', 'tweet', 'time', 'coordinates', 'retweeted', 'place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ID column (because we removed user information)\n",
    "unique_id = np.arange(len(df_tweet))\n",
    "df_tweet['id'] = unique_id + 1\n",
    "df_tweet = df_tweet[['id', 'location', 'tweet', 'time', 'coordinates', 'retweeted', 'place']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "      <th>time</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ingersoll, Ontario</td>\n",
       "      <td>New video from Aug. 17th intercept of severe t...</td>\n",
       "      <td>2020-12-31 02:58:41</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cleveland, OH</td>\n",
       "      <td>Iconic tree along Lake Erie comes down at Hunt...</td>\n",
       "      <td>2020-12-31 02:49:02</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cleveland, Ohio</td>\n",
       "      <td>The 3News Lake Erie Nearshore Forecast... http...</td>\n",
       "      <td>2020-12-31 02:45:33</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Northern Virginia</td>\n",
       "      <td>RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...</td>\n",
       "      <td>2020-12-31 02:44:01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ohio, USA</td>\n",
       "      <td>@grneyedmusiklvr We get some amazing sunrises ...</td>\n",
       "      <td>2020-12-31 02:40:12</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-31 02:27:11</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-31 01:58:38</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Denver, PA</td>\n",
       "      <td>Possibly one of the most iconic relics of the ...</td>\n",
       "      <td>2020-12-31 01:47:15</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>RT @Floatie_Flo: Received an offer to finish m...</td>\n",
       "      <td>2020-12-31 01:43:36</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @HCChargers: What's better than a rivalry g...</td>\n",
       "      <td>2020-12-31 01:31:34</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Lorain, Ohio</td>\n",
       "      <td>RT @LorainLHouse: The certificate from Lake Er...</td>\n",
       "      <td>2020-12-31 01:28:43</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...</td>\n",
       "      <td>2020-12-31 01:19:52</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @pressley_devin: ✟ Blessed to receive my fi...</td>\n",
       "      <td>2020-12-31 01:15:15</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-31 01:13:16</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>Ima drive da pickup into Lake Erie Dey lose ht...</td>\n",
       "      <td>2020-12-31 00:55:32</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>RT @ScaleraNick: #AGTG Blessed to have receive...</td>\n",
       "      <td>2020-12-31 00:47:11</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>wicked tuna</td>\n",
       "      <td>RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...</td>\n",
       "      <td>2020-12-31 00:34:04</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-31 00:21:47</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @LakeErieTFXC: Recognizing Lake Erie Colleg...</td>\n",
       "      <td>2020-12-30 23:55:24</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>13 minutes from tip on the shores of Lake Erie...</td>\n",
       "      <td>2020-12-30 23:54:04</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...</td>\n",
       "      <td>2020-12-30 23:51:14</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Eureka, California</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 23:50:59</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Northern Virginia</td>\n",
       "      <td>NEW VIDEO: Trophy Steelhead Trout Fishing in P...</td>\n",
       "      <td>2020-12-30 23:48:40</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>https://t.co/kttJ3sezZn</td>\n",
       "      <td>2020-12-30 23:47:18</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 23:44:12</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @Floatie_Flo: Received an offer to finish m...</td>\n",
       "      <td>2020-12-30 23:33:39</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>None</td>\n",
       "      <td>@JR_Buf740iL @CARandDRIVER haah just found it ...</td>\n",
       "      <td>2020-12-30 23:31:00</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>London, England</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 23:09:40</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>RT @JacksonJyquan: Blessed to receive an offer...</td>\n",
       "      <td>2020-12-30 23:08:33</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Geneva, Ohio</td>\n",
       "      <td>RT @LakeErieTFXC: Recognizing Lake Erie Colleg...</td>\n",
       "      <td>2020-12-30 23:05:12</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Painesville, OH</td>\n",
       "      <td>Recognizing Lake Erie College Track and Field ...</td>\n",
       "      <td>2020-12-30 22:59:36</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Painesville, OH</td>\n",
       "      <td>Recognizing Lake Erie College Track and Field ...</td>\n",
       "      <td>2020-12-30 22:58:17</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 22:54:39</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>Yay Area</td>\n",
       "      <td>RT @Floatie_Flo: Received an offer to finish m...</td>\n",
       "      <td>2020-12-30 22:50:23</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>Check out MTH Rail King 30-7167 Stock Car - Be...</td>\n",
       "      <td>2020-12-30 22:48:52</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Oblong, Il.</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 22:35:58</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>Gastonia, NC</td>\n",
       "      <td>RT @pressley_devin: ✟ Blessed to receive my fi...</td>\n",
       "      <td>2020-12-30 22:27:20</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>Beaumont, CA</td>\n",
       "      <td>RT @Floatie_Flo: Received an offer to finish m...</td>\n",
       "      <td>2020-12-30 22:23:45</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 22:20:29</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 22:12:29</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @XavierRogers42: Thanking God for blessing ...</td>\n",
       "      <td>2020-12-30 22:06:24</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>Toledo, Ohio</td>\n",
       "      <td>RT @DowntownToledo: Awesome photo taken this m...</td>\n",
       "      <td>2020-12-30 22:06:14</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 22:03:39</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>Duluth, MN</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 22:01:22</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @pressley_devin: ✟ Blessed to receive my fi...</td>\n",
       "      <td>2020-12-30 21:51:04</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @Floatie_Flo: Received an offer to finish m...</td>\n",
       "      <td>2020-12-30 21:45:43</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>The 3rd Planet</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 21:38:40</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Long Beach, CA</td>\n",
       "      <td>RT @Floatie_Flo: Received an offer to finish m...</td>\n",
       "      <td>2020-12-30 21:36:43</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>Elmira, NY</td>\n",
       "      <td>Medical students from the Lake Erie College of...</td>\n",
       "      <td>2020-12-30 21:35:07</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>RT @WIRED: When nasty storms pummel the Great ...</td>\n",
       "      <td>2020-12-30 21:33:10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id            location                                              tweet  \\\n",
       "0    1  Ingersoll, Ontario  New video from Aug. 17th intercept of severe t...   \n",
       "1    2       Cleveland, OH  Iconic tree along Lake Erie comes down at Hunt...   \n",
       "2    3     Cleveland, Ohio  The 3News Lake Erie Nearshore Forecast... http...   \n",
       "3    4  Northern Virginia   RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...   \n",
       "4    5           Ohio, USA  @grneyedmusiklvr We get some amazing sunrises ...   \n",
       "5    6                None  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "6    7                None  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "7    8          Denver, PA  Possibly one of the most iconic relics of the ...   \n",
       "8    9     California, USA  RT @Floatie_Flo: Received an offer to finish m...   \n",
       "9   10                None  RT @HCChargers: What's better than a rivalry g...   \n",
       "10  11        Lorain, Ohio  RT @LorainLHouse: The certificate from Lake Er...   \n",
       "11  12                None  RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...   \n",
       "12  13                None  RT @pressley_devin: ✟ Blessed to receive my fi...   \n",
       "13  14       Las Vegas, NV  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "14  15                None  Ima drive da pickup into Lake Erie Dey lose ht...   \n",
       "15  16         Houston, TX  RT @ScaleraNick: #AGTG Blessed to have receive...   \n",
       "16  17        wicked tuna   RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...   \n",
       "17  18                None  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "18  19                None  RT @LakeErieTFXC: Recognizing Lake Erie Colleg...   \n",
       "19  20                Ohio  13 minutes from tip on the shores of Lake Erie...   \n",
       "20  21      Washington, DC  RT @Gabby_Hoffman: NEW VIDEO: Trophy Steelhead...   \n",
       "21  22  Eureka, California  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "22  23  Northern Virginia   NEW VIDEO: Trophy Steelhead Trout Fishing in P...   \n",
       "23  24         Los Angeles                            https://t.co/kttJ3sezZn   \n",
       "24  25                None  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "25  26                None  RT @Floatie_Flo: Received an offer to finish m...   \n",
       "26  27                None  @JR_Buf740iL @CARandDRIVER haah just found it ...   \n",
       "27  28     London, England  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "28  29           Miami, FL  RT @JacksonJyquan: Blessed to receive an offer...   \n",
       "29  30        Geneva, Ohio  RT @LakeErieTFXC: Recognizing Lake Erie Colleg...   \n",
       "30  31     Painesville, OH  Recognizing Lake Erie College Track and Field ...   \n",
       "31  32     Painesville, OH  Recognizing Lake Erie College Track and Field ...   \n",
       "32  33       Paris, France  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "33  34            Yay Area  RT @Floatie_Flo: Received an offer to finish m...   \n",
       "34  35              U.S.A.  Check out MTH Rail King 30-7167 Stock Car - Be...   \n",
       "35  36         Oblong, Il.  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "36  37        Gastonia, NC  RT @pressley_devin: ✟ Blessed to receive my fi...   \n",
       "37  38        Beaumont, CA  RT @Floatie_Flo: Received an offer to finish m...   \n",
       "38  39                None  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "39  40                None  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "40  41                None  RT @XavierRogers42: Thanking God for blessing ...   \n",
       "41  42        Toledo, Ohio  RT @DowntownToledo: Awesome photo taken this m...   \n",
       "42  43                None  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "43  44          Duluth, MN  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "44  45                None  RT @pressley_devin: ✟ Blessed to receive my fi...   \n",
       "45  46                None  RT @Floatie_Flo: Received an offer to finish m...   \n",
       "46  47      The 3rd Planet  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "47  48      Long Beach, CA  RT @Floatie_Flo: Received an offer to finish m...   \n",
       "48  49          Elmira, NY  Medical students from the Lake Erie College of...   \n",
       "49  50  Sheffield, England  RT @WIRED: When nasty storms pummel the Great ...   \n",
       "\n",
       "                  time coordinates  retweeted place  \n",
       "0  2020-12-31 02:58:41        None      False  None  \n",
       "1  2020-12-31 02:49:02        None      False  None  \n",
       "2  2020-12-31 02:45:33        None      False  None  \n",
       "3  2020-12-31 02:44:01        None      False  None  \n",
       "4  2020-12-31 02:40:12        None      False  None  \n",
       "5  2020-12-31 02:27:11        None      False  None  \n",
       "6  2020-12-31 01:58:38        None      False  None  \n",
       "7  2020-12-31 01:47:15        None      False  None  \n",
       "8  2020-12-31 01:43:36        None      False  None  \n",
       "9  2020-12-31 01:31:34        None      False  None  \n",
       "10 2020-12-31 01:28:43        None      False  None  \n",
       "11 2020-12-31 01:19:52        None      False  None  \n",
       "12 2020-12-31 01:15:15        None      False  None  \n",
       "13 2020-12-31 01:13:16        None      False  None  \n",
       "14 2020-12-31 00:55:32        None      False  None  \n",
       "15 2020-12-31 00:47:11        None      False  None  \n",
       "16 2020-12-31 00:34:04        None      False  None  \n",
       "17 2020-12-31 00:21:47        None      False  None  \n",
       "18 2020-12-30 23:55:24        None      False  None  \n",
       "19 2020-12-30 23:54:04        None      False  None  \n",
       "20 2020-12-30 23:51:14        None      False  None  \n",
       "21 2020-12-30 23:50:59        None      False  None  \n",
       "22 2020-12-30 23:48:40        None      False  None  \n",
       "23 2020-12-30 23:47:18        None      False  None  \n",
       "24 2020-12-30 23:44:12        None      False  None  \n",
       "25 2020-12-30 23:33:39        None      False  None  \n",
       "26 2020-12-30 23:31:00        None      False  None  \n",
       "27 2020-12-30 23:09:40        None      False  None  \n",
       "28 2020-12-30 23:08:33        None      False  None  \n",
       "29 2020-12-30 23:05:12        None      False  None  \n",
       "30 2020-12-30 22:59:36        None      False  None  \n",
       "31 2020-12-30 22:58:17        None      False  None  \n",
       "32 2020-12-30 22:54:39        None      False  None  \n",
       "33 2020-12-30 22:50:23        None      False  None  \n",
       "34 2020-12-30 22:48:52        None      False  None  \n",
       "35 2020-12-30 22:35:58        None      False  None  \n",
       "36 2020-12-30 22:27:20        None      False  None  \n",
       "37 2020-12-30 22:23:45        None      False  None  \n",
       "38 2020-12-30 22:20:29        None      False  None  \n",
       "39 2020-12-30 22:12:29        None      False  None  \n",
       "40 2020-12-30 22:06:24        None      False  None  \n",
       "41 2020-12-30 22:06:14        None      False  None  \n",
       "42 2020-12-30 22:03:39        None      False  None  \n",
       "43 2020-12-30 22:01:22        None      False  None  \n",
       "44 2020-12-30 21:51:04        None      False  None  \n",
       "45 2020-12-30 21:45:43        None      False  None  \n",
       "46 2020-12-30 21:38:40        None      False  None  \n",
       "47 2020-12-30 21:36:43        None      False  None  \n",
       "48 2020-12-30 21:35:07        None      False  None  \n",
       "49 2020-12-30 21:33:10        None      False  None  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "      <th>time</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74977</th>\n",
       "      <td>74978</td>\n",
       "      <td>Canberra</td>\n",
       "      <td>#NewYork state #homes covered with amazing #ic...</td>\n",
       "      <td>2020-03-04 21:30:32</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74978</th>\n",
       "      <td>74979</td>\n",
       "      <td>Desubicada</td>\n",
       "      <td>RT @john_kucko: 19 Days Until Spring:  Until t...</td>\n",
       "      <td>2020-03-04 21:27:07</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74979</th>\n",
       "      <td>74980</td>\n",
       "      <td>Desubicada</td>\n",
       "      <td>RT @StormchaserUKEU: WOW... Absolutely fantast...</td>\n",
       "      <td>2020-03-04 21:26:57</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74980</th>\n",
       "      <td>74981</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://t.co/yoTW7fCezG</td>\n",
       "      <td>2020-03-04 21:23:13</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74981</th>\n",
       "      <td>74982</td>\n",
       "      <td>Congleton, Cheshire. UK</td>\n",
       "      <td>After extreme winds, homes along Lake Erie cov...</td>\n",
       "      <td>2020-03-04 21:13:58</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                 location  \\\n",
       "74977  74978                 Canberra   \n",
       "74978  74979               Desubicada   \n",
       "74979  74980               Desubicada   \n",
       "74980  74981            United States   \n",
       "74981  74982  Congleton, Cheshire. UK   \n",
       "\n",
       "                                                   tweet                time  \\\n",
       "74977  #NewYork state #homes covered with amazing #ic... 2020-03-04 21:30:32   \n",
       "74978  RT @john_kucko: 19 Days Until Spring:  Until t... 2020-03-04 21:27:07   \n",
       "74979  RT @StormchaserUKEU: WOW... Absolutely fantast... 2020-03-04 21:26:57   \n",
       "74980                            https://t.co/yoTW7fCezG 2020-03-04 21:23:13   \n",
       "74981  After extreme winds, homes along Lake Erie cov... 2020-03-04 21:13:58   \n",
       "\n",
       "      coordinates  retweeted place  \n",
       "74977        None      False  None  \n",
       "74978        None      False  None  \n",
       "74979        None      False  None  \n",
       "74980        None      False  None  \n",
       "74981        None      False  None  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iconic tree along Lake Erie comes down at Huntington Beach in Bay Village https://t.co/DFMuyXv2om https://t.co/MW7k8kSIzw'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.tweet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.place[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning tweets in the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets clean tweets after labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean each tweet in our dataframe using the preprocessor module\n",
    "# tweet_clean = []\n",
    "# for tweet in df_tweet['tweet']:\n",
    "#     cleaned = p.clean(tweet)\n",
    "#     tweet_clean.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store as a new dataframe\n",
    "# df_tweet_clean = df_tweet.copy()\n",
    "# df_tweet_clean['tweet'] = tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweet_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataframe as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rapiduser\\\\Documents\\\\WaterQualityPerception\\\\Pierre\\\\WaterQualityPerceptionMP2020'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking current working directory\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as CSV to a relative path\n",
    "#df_tweet.to_csv(f\"..\\\\..\\\\Data\\\\lakeerie_{year_from}_{year_to}.csv\")\n",
    "df_tweet.to_csv(f\"..\\\\..\\\\Data\\\\lakeerie_{year_from}_{year_to}links.csv\")\n",
    "#df_tweet_clean.to_csv(f\"..\\\\..\\\\Data\\\\utahlake_{year}.csv\")\n",
    "#df_tweet_clean.to_csv(\"..\\\\..\\\\Data\\\\scraped_tweets_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
