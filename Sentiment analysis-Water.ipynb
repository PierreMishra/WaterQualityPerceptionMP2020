{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re, string, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "#        if tag.startswith(\"NN\"):\n",
    "#            pos = 'n'\n",
    "#        elif tag.startswith('VB'):\n",
    "#            pos = 'v'\n",
    "#        else:\n",
    "#            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token\n",
    "\n",
    "def get_tweets_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\benha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\benha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:\\\\Users\\\\benha\\\\OneDrive\\\\Desktop\\\\Utahlaketweets\\\\utahlake_2016.csv', engine='python',\n",
    "       names = ['id','text','time', 'utahlake', 'waterquality', 'positive','current'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algae', 143), ('water', 127), ('bloom', 120), ('toxic', 80), ('utah', 54), ('algal', 50), ('clean', 47), ('get', 46), ('people', 41), ('like', 39)]\n",
      "Accuracy is: 0.8222222222222222\n",
      "Most Informative Features\n",
      "                   bloom = True           Water_ : Non_wa =    228.8 : 1.0\n",
      "                   nasty = True           Water_ : Non_wa =     30.3 : 1.0\n",
      "                 utahdeq = True           Water_ : Non_wa =     19.5 : 1.0\n",
      "                   clean = True           Water_ : Non_wa =     15.9 : 1.0\n",
      "                 warning = True           Water_ : Non_wa =     15.3 : 1.0\n",
      "                  health = True           Water_ : Non_wa =     13.8 : 1.0\n",
      "                  closed = True           Water_ : Non_wa =     13.3 : 1.0\n",
      "                    ncga = True           Water_ : Non_wa =     13.3 : 1.0\n",
      "           ncpolicywatch = True           Water_ : Non_wa =     13.3 : 1.0\n",
      "                    uchd = True           Water_ : Non_wa =     13.3 : 1.0\n",
      "                  affect = True           Water_ : Non_wa =     12.4 : 1.0\n",
      "                   avoid = True           Water_ : Non_wa =     12.4 : 1.0\n",
      "                    blue = True           Water_ : Non_wa =     12.4 : 1.0\n",
      "                possibly = True           Water_ : Non_wa =     10.9 : 1.0\n",
      "                 science = True           Water_ : Non_wa =     10.9 : 1.0\n",
      "                  sewage = True           Water_ : Non_wa =     10.9 : 1.0\n",
      "               situation = True           Water_ : Non_wa =     10.9 : 1.0\n",
      "             spencerjcox = True           Water_ : Non_wa =     10.9 : 1.0\n",
      "                   swarm = True           Water_ : Non_wa =     10.9 : 1.0\n",
      "                 quality = True           Water_ : Non_wa =      9.9 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df= pd.read_csv(\n",
    "        'C:\\\\Users\\\\benha\\\\OneDrive\\\\Desktop\\\\Utahlaketweets\\\\utahlake_2016.csv', engine='python',\n",
    "        names = ['id','text','time', 'utahlake', 'waterquality', 'positive','current'],)\n",
    "    repetitive = ['Utah Lake', 'UtahLake', 'Utah lake', 'Utahlake', 'utahlake', '&amp', 'utah', 'lake',\n",
    "                  'Jordan Lake', 'Jordan lake',\"n't\",\"s't\",'1','2','3','4','5','6','7','8','9','0',\"'re\",\"'d\",\"cuz\",\"``\",\"--\"]\n",
    "    for i in repetitive:  \n",
    "        df['text'] = df['text'].str.replace(i, '')\n",
    "    for i in string.punctuation:\n",
    "       df['text'] = df['text'].str.replace(i, ' ')\n",
    "    #df = df[1:]\n",
    "    df=df[df.utahlake!='0']\n",
    "    df= df[df['text'].str[:2]!='RT']\n",
    "    df = df.fillna('-1')\n",
    "    positive = df['text'][df['waterquality']=='Yes'].tolist()\n",
    "    negative = df['text'][df['waterquality']=='No'].tolist()\n",
    "    #neutral = df['text'][df['waterquality']=='Not sure'].tolist()\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    positive_tokens = [word_tokenize(i) for i in positive]\n",
    "    negative_tokens = [word_tokenize(i) for i in negative]\n",
    "    #neutral_tokens = [word_tokenize(i) for i in neutral]\n",
    "\n",
    "    positive_cleaned_tokens_list = []\n",
    "    negative_cleaned_tokens_list = []\n",
    "    #neutral_cleaned_tokens_list = []\n",
    "\n",
    "    for tokens in positive_tokens:\n",
    "        positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words,))\n",
    "\n",
    "    for tokens in negative_tokens:\n",
    "        negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "    #for tokens in neutral_tokens:\n",
    "    #    neutral_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "        \n",
    "    all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "\n",
    "    freq_dist_pos = FreqDist(all_pos_words)\n",
    "    print(freq_dist_pos.most_common(10))\n",
    "\n",
    "    positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n",
    "    negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n",
    "    #neutral_tokens_for_model = get_tweets_for_model(neutral_cleaned_tokens_list)\n",
    "\n",
    "    positive_dataset = [(tweet_dict, \"Water_quality\")\n",
    "                         for tweet_dict in positive_tokens_for_model]\n",
    "\n",
    "    negative_dataset = [(tweet_dict, \"Non_water_quality\")\n",
    "                         for tweet_dict in negative_tokens_for_model]\n",
    "    #neutral_dataset = [(tweet_dict, \"Neutral\")\n",
    "    #                     for tweet_dict in neutral_tokens_for_model]\n",
    "\n",
    "    dataset=positive_dataset+negative_dataset#+neutral_dataset\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    train_data = dataset[:1800]\n",
    "    test_data = dataset[1800:]\n",
    "\n",
    "    classifier_water = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "    print(\"Accuracy is:\", classify.accuracy(classifier_water, test_data))\n",
    "\n",
    "    print(classifier_water.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('go', 83), ('love', 81), ('good', 79), ('get', 69), ('day', 58), ('like', 52), ('great', 50), ('quot', 50), ('one', 47), ('time', 47)]\n",
      "Accuracy is: 0.7022900763358778\n",
      "Most Informative Features\n",
      "                   algae = True           Negati : Positi =     19.6 : 1.0\n",
      "                   thank = True           Positi : Negati =     16.2 : 1.0\n",
      "                     due = True           Negati : Positi =     12.7 : 1.0\n",
      "                   bloom = True           Negati : Positi =     11.4 : 1.0\n",
      "                   green = True           Negati : Positi =     10.3 : 1.0\n",
      "                   cause = True           Negati : Positi =      9.8 : 1.0\n",
      "                     sad = True           Negati : Positi =      9.0 : 1.0\n",
      "               goodnight = True           Positi : Negati =      8.8 : 1.0\n",
      "                    swim = True           Negati : Positi =      7.9 : 1.0\n",
      "                    dump = True           Negati : Positi =      6.5 : 1.0\n",
      "                    fire = True           Negati : Positi =      6.5 : 1.0\n",
      "                 twitter = True           Positi : Negati =      6.5 : 1.0\n",
      "                 amazing = True           Positi : Negati =      6.0 : 1.0\n",
      "                      hi = True           Positi : Negati =      6.0 : 1.0\n",
      "                      co = True           Negati : Positi =      6.0 : 1.0\n",
      "                 problem = True           Negati : Positi =      5.9 : 1.0\n",
      "                    damn = True           Negati : Positi =      5.5 : 1.0\n",
      "                    fuck = True           Negati : Positi =      5.5 : 1.0\n",
      "                    near = True           Negati : Positi =      5.5 : 1.0\n",
      "                  thanks = True           Positi : Negati =      5.5 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df= pd.read_csv(\n",
    "        'C:\\\\Users\\\\benha\\\\OneDrive\\\\Desktop\\\\Utahlaketweets\\\\utahlake_2016.csv', engine='python',\n",
    "        names = ['id','text','time', 'utahlake', 'waterquality', 'positive','current'],)\n",
    "    repetitive = ['Utah Lake', 'UtahLake', 'Utah lake', 'Utahlake', 'utah lake', 'utahlake', '&amp',\n",
    "                  'Jordan Lake', 'Jordan lake',\"n't\",\"s't\",'utah','1','2','3','4','5','6','7','8','9','0',\"'re\",\"'d\",\"cuz\",\"``\",\"--\"]\n",
    "    for i in repetitive:  \n",
    "        df['text'] = df['text'].str.replace(i, '')\n",
    "    for i in string.punctuation:\n",
    "       df['text'] = df['text'].str.replace(i, ' ')\n",
    "    #df = df[1:]\n",
    "    df=df[df.utahlake!='0']\n",
    "    df= df[df['text'].str[:2]!='RT']\n",
    "    df = df.fillna('-1')\n",
    "    positive = df['text'][df['positive']=='Positive'].tolist()\n",
    "    negative = df['text'][df['positive']=='Negative'].tolist()\n",
    "    #neutral = df['text'][df['positive']=='Neutral'].tolist()\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    positive_tokens = [word_tokenize(i) for i in positive]\n",
    "    negative_tokens = [word_tokenize(i) for i in negative]\n",
    "   # neutral_tokens = [word_tokenize(i) for i in neutral]\n",
    "\n",
    "    positive_cleaned_tokens_list = []\n",
    "    negative_cleaned_tokens_list = []\n",
    "   # neutral_cleaned_tokens_list = []\n",
    "\n",
    "    for tokens in positive_tokens:\n",
    "        positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "    for tokens in negative_tokens:\n",
    "        negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "    #for tokens in neutral_tokens:\n",
    "     #   neutral_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "        \n",
    "    all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "\n",
    "    freq_dist_pos = FreqDist(all_pos_words)\n",
    "    print(freq_dist_pos.most_common(10))\n",
    "\n",
    "    positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n",
    "    negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n",
    "    #neutral_tokens_for_model = get_tweets_for_model(neutral_cleaned_tokens_list)\n",
    "\n",
    "    positive_dataset = [(tweet_dict, \"Positive\")\n",
    "                         for tweet_dict in positive_tokens_for_model]\n",
    "\n",
    "    negative_dataset = [(tweet_dict, \"Negative\")\n",
    "                         for tweet_dict in negative_tokens_for_model]\n",
    "    #neutral_dataset = [(tweet_dict, \"Neutral\")\n",
    "                      #   for tweet_dict in neutral_tokens_for_model]\n",
    "\n",
    "    dataset=positive_dataset+negative_dataset#+neutral_dataset\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    train_data = dataset[:1900]\n",
    "    test_data = dataset[1900:]\n",
    "\n",
    "    classifier_positive = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "    print(\"Accuracy is:\", classify.accuracy(classifier_positive, test_data))\n",
    "\n",
    "    print(classifier_positive.show_most_informative_features(20))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>utahlake</th>\n",
       "      <th>waterquality</th>\n",
       "      <th>positive</th>\n",
       "      <th>current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The real Freak Lake  as envisioned while I wro...</td>\n",
       "      <td>12/31/2016 4:27</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>fav to come iceskating on ⛸</td>\n",
       "      <td>12/29/2016 20:51</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>KDMA   let s go run into  and freeze to deat...</td>\n",
       "      <td>12/22/2016 1:52</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>rcfullmer  Tsebresos  DexFenik Ew   is so nasty</td>\n",
       "      <td>12/21/2016 20:32</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>WindWolfArt  Tsebresos  DexFenik Or if you ar...</td>\n",
       "      <td>12/21/2016 20:21</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>-1</td>\n",
       "      <td>Interior  BlueRidgeNPS  SecretaryZinke “    B...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>-1</td>\n",
       "      <td>TriangleBiways Great time capsule     The Sea...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>-1</td>\n",
       "      <td>“A life worth living is one of compassion  And...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>-1</td>\n",
       "      <td>After yays story about PFOAs  PFAs etc in   Ca...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>-1</td>\n",
       "      <td>TownofCary hi  Read about elevated chemicals ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text              time  \\\n",
       "4      4  The real Freak Lake  as envisioned while I wro...   12/31/2016 4:27   \n",
       "5      5                        fav to come iceskating on ⛸  12/29/2016 20:51   \n",
       "6      6    KDMA   let s go run into  and freeze to deat...   12/22/2016 1:52   \n",
       "7      7   rcfullmer  Tsebresos  DexFenik Ew   is so nasty   12/21/2016 20:32   \n",
       "8      8   WindWolfArt  Tsebresos  DexFenik Or if you ar...  12/21/2016 20:21   \n",
       "...   ..                                                ...               ...   \n",
       "1392  -1   Interior  BlueRidgeNPS  SecretaryZinke “    B...                -1   \n",
       "1395  -1   TriangleBiways Great time capsule     The Sea...                -1   \n",
       "1396  -1  “A life worth living is one of compassion  And...                -1   \n",
       "1397  -1  After yays story about PFOAs  PFAs etc in   Ca...                -1   \n",
       "1403  -1   TownofCary hi  Read about elevated chemicals ...                -1   \n",
       "\n",
       "     utahlake waterquality  positive current  \n",
       "4           1          Yes  Negative      -1  \n",
       "5           1           No  Positive      -1  \n",
       "6           1           No   Neutral       1  \n",
       "7           1          Yes  Negative       1  \n",
       "8           1           No  Positive       0  \n",
       "...       ...          ...       ...     ...  \n",
       "1392        1           No  Positive      -1  \n",
       "1395        1           No   Neutral      -1  \n",
       "1396        1           No  Positive      -1  \n",
       "1397        1          Yes  Negative      -1  \n",
       "1403        1          Yes  Negative      -1  \n",
       "\n",
       "[1110 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>waterquality</th>\n",
       "      <th>positive</th>\n",
       "      <th>current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2</td>\n",
       "      <td>Provo, UT</td>\n",
       "      <td>No matter how you fish at Utah Lake, we hope  ...</td>\n",
       "      <td>12/31/2016 21:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3</td>\n",
       "      <td>Provo, UT</td>\n",
       "      <td>What's YOUR favorite activity on the ice of Ut...</td>\n",
       "      <td>12/31/2016 18:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunset at Utah Lake, 5 minutes drive from my h...</td>\n",
       "      <td>12/31/2016 1:26</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-111.735, 40...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x000001F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>5</td>\n",
       "      <td>Utah, USA</td>\n",
       "      <td>This is in our back yard! Toxic algae in Utah ...</td>\n",
       "      <td>12/31/2016 0:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6</td>\n",
       "      <td>Utah, USA</td>\n",
       "      <td>This is in our back yard! Toxic algae in Utah ...</td>\n",
       "      <td>12/31/2016 0:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.0</th>\n",
       "      <td>6806</td>\n",
       "      <td>Provo, UT</td>\n",
       "      <td>Fav to come to a insta meet I just planned w a...</td>\n",
       "      <td>1/2/2016 7:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x000001F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806.0</th>\n",
       "      <td>6807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks to the Jenne and Camp families, this ic...</td>\n",
       "      <td>1/1/2016 20:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807.0</th>\n",
       "      <td>6808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @GarrettElls: Yesterday was fun too bad the...</td>\n",
       "      <td>1/1/2016 19:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808.0</th>\n",
       "      <td>6809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yesterday was fun too bad the Utah lake ones d...</td>\n",
       "      <td>1/1/2016 19:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809.0</th>\n",
       "      <td>6810</td>\n",
       "      <td>Sandy, UT</td>\n",
       "      <td>Final sunset of 2015. #twitter #sunset #utahla...</td>\n",
       "      <td>1/1/2016 2:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6809 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   location                                               text  \\\n",
       "1.0        2  Provo, UT  No matter how you fish at Utah Lake, we hope  ...   \n",
       "2.0        3  Provo, UT  What's YOUR favorite activity on the ice of Ut...   \n",
       "3.0        4        NaN  Sunset at Utah Lake, 5 minutes drive from my h...   \n",
       "4.0        5  Utah, USA  This is in our back yard! Toxic algae in Utah ...   \n",
       "5.0        6  Utah, USA  This is in our back yard! Toxic algae in Utah ...   \n",
       "...      ...        ...                                                ...   \n",
       "6805.0  6806  Provo, UT  Fav to come to a insta meet I just planned w a...   \n",
       "6806.0  6807        NaN  Thanks to the Jenne and Camp families, this ic...   \n",
       "6807.0  6808        NaN  RT @GarrettElls: Yesterday was fun too bad the...   \n",
       "6808.0  6809        NaN  Yesterday was fun too bad the Utah lake ones d...   \n",
       "6809.0  6810  Sandy, UT  Final sunset of 2015. #twitter #sunset #utahla...   \n",
       "\n",
       "                    time                                       waterquality  \\\n",
       "1.0     12/31/2016 21:45                                                NaN   \n",
       "2.0     12/31/2016 18:20                                                NaN   \n",
       "3.0      12/31/2016 1:26  {'type': 'Point', 'coordinates': [-111.735, 40...   \n",
       "4.0      12/31/2016 0:50                                                NaN   \n",
       "5.0      12/31/2016 0:50                                                NaN   \n",
       "...                  ...                                                ...   \n",
       "6805.0     1/2/2016 7:12                                                NaN   \n",
       "6806.0    1/1/2016 20:19                                                NaN   \n",
       "6807.0    1/1/2016 19:39                                                NaN   \n",
       "6808.0    1/1/2016 19:38                                                NaN   \n",
       "6809.0     1/1/2016 2:04                                                NaN   \n",
       "\n",
       "       positive                                            current  \n",
       "1.0       FALSE                                                NaN  \n",
       "2.0       FALSE                                                NaN  \n",
       "3.0       FALSE  Place(_api=<tweepy.api.API object at 0x000001F...  \n",
       "4.0       FALSE                                                NaN  \n",
       "5.0       FALSE                                                NaN  \n",
       "...         ...                                                ...  \n",
       "6805.0    FALSE  Place(_api=<tweepy.api.API object at 0x000001F...  \n",
       "6806.0    FALSE                                                NaN  \n",
       "6807.0    FALSE                                                NaN  \n",
       "6808.0    FALSE                                                NaN  \n",
       "6809.0    FALSE                                                NaN  \n",
       "\n",
       "[6809 rows x 7 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###PREDICTION\n",
    "dataset= pd.read_csv(\n",
    "        'C:\\\\Users\\\\benha\\\\OneDrive\\\\Desktop\\\\Utahlaketweets\\\\utahlake_2016_links.csv', \n",
    "        names = ['id','location','text','time', 'waterquality', 'positive','current'])\n",
    "dataset = dataset[1:]\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "WATER_pre=[]\n",
    "POS_pre=[]\n",
    "for i in range(1,len(dataset)+1):\n",
    "    tweet = dataset.text[i]\n",
    "    tokens = remove_noise(word_tokenize(tweet))\n",
    "    WATER_pre.append(classifier_water.classify(dict([token, True] for token in tokens)))\n",
    "    POS_pre.append(classifier_positive.classify(dict([token, True] for token in tokens)))\n",
    "dataset['water_prediction']= WATER_pre\n",
    "dataset['pos_prediction']=POS_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>waterquality</th>\n",
       "      <th>positive</th>\n",
       "      <th>current</th>\n",
       "      <th>water_prediction</th>\n",
       "      <th>pos_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2</td>\n",
       "      <td>Provo, UT</td>\n",
       "      <td>No matter how you fish at Utah Lake, we hope  ...</td>\n",
       "      <td>12/31/2016 21:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non_water_quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3</td>\n",
       "      <td>Provo, UT</td>\n",
       "      <td>What's YOUR favorite activity on the ice of Ut...</td>\n",
       "      <td>12/31/2016 18:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non_water_quality</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunset at Utah Lake, 5 minutes drive from my h...</td>\n",
       "      <td>12/31/2016 1:26</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-111.735, 40...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x000001F...</td>\n",
       "      <td>Non_water_quality</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>5</td>\n",
       "      <td>Utah, USA</td>\n",
       "      <td>This is in our back yard! Toxic algae in Utah ...</td>\n",
       "      <td>12/31/2016 0:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Water_quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6</td>\n",
       "      <td>Utah, USA</td>\n",
       "      <td>This is in our back yard! Toxic algae in Utah ...</td>\n",
       "      <td>12/31/2016 0:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Water_quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805.0</th>\n",
       "      <td>6806</td>\n",
       "      <td>Provo, UT</td>\n",
       "      <td>Fav to come to a insta meet I just planned w a...</td>\n",
       "      <td>1/2/2016 7:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x000001F...</td>\n",
       "      <td>Non_water_quality</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806.0</th>\n",
       "      <td>6807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks to the Jenne and Camp families, this ic...</td>\n",
       "      <td>1/1/2016 20:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non_water_quality</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807.0</th>\n",
       "      <td>6808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @GarrettElls: Yesterday was fun too bad the...</td>\n",
       "      <td>1/1/2016 19:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Water_quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808.0</th>\n",
       "      <td>6809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yesterday was fun too bad the Utah lake ones d...</td>\n",
       "      <td>1/1/2016 19:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Water_quality</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809.0</th>\n",
       "      <td>6810</td>\n",
       "      <td>Sandy, UT</td>\n",
       "      <td>Final sunset of 2015. #twitter #sunset #utahla...</td>\n",
       "      <td>1/1/2016 2:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non_water_quality</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6809 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   location                                               text  \\\n",
       "1.0        2  Provo, UT  No matter how you fish at Utah Lake, we hope  ...   \n",
       "2.0        3  Provo, UT  What's YOUR favorite activity on the ice of Ut...   \n",
       "3.0        4        NaN  Sunset at Utah Lake, 5 minutes drive from my h...   \n",
       "4.0        5  Utah, USA  This is in our back yard! Toxic algae in Utah ...   \n",
       "5.0        6  Utah, USA  This is in our back yard! Toxic algae in Utah ...   \n",
       "...      ...        ...                                                ...   \n",
       "6805.0  6806  Provo, UT  Fav to come to a insta meet I just planned w a...   \n",
       "6806.0  6807        NaN  Thanks to the Jenne and Camp families, this ic...   \n",
       "6807.0  6808        NaN  RT @GarrettElls: Yesterday was fun too bad the...   \n",
       "6808.0  6809        NaN  Yesterday was fun too bad the Utah lake ones d...   \n",
       "6809.0  6810  Sandy, UT  Final sunset of 2015. #twitter #sunset #utahla...   \n",
       "\n",
       "                    time                                       waterquality  \\\n",
       "1.0     12/31/2016 21:45                                                NaN   \n",
       "2.0     12/31/2016 18:20                                                NaN   \n",
       "3.0      12/31/2016 1:26  {'type': 'Point', 'coordinates': [-111.735, 40...   \n",
       "4.0      12/31/2016 0:50                                                NaN   \n",
       "5.0      12/31/2016 0:50                                                NaN   \n",
       "...                  ...                                                ...   \n",
       "6805.0     1/2/2016 7:12                                                NaN   \n",
       "6806.0    1/1/2016 20:19                                                NaN   \n",
       "6807.0    1/1/2016 19:39                                                NaN   \n",
       "6808.0    1/1/2016 19:38                                                NaN   \n",
       "6809.0     1/1/2016 2:04                                                NaN   \n",
       "\n",
       "       positive                                            current  \\\n",
       "1.0       FALSE                                                NaN   \n",
       "2.0       FALSE                                                NaN   \n",
       "3.0       FALSE  Place(_api=<tweepy.api.API object at 0x000001F...   \n",
       "4.0       FALSE                                                NaN   \n",
       "5.0       FALSE                                                NaN   \n",
       "...         ...                                                ...   \n",
       "6805.0    FALSE  Place(_api=<tweepy.api.API object at 0x000001F...   \n",
       "6806.0    FALSE                                                NaN   \n",
       "6807.0    FALSE                                                NaN   \n",
       "6808.0    FALSE                                                NaN   \n",
       "6809.0    FALSE                                                NaN   \n",
       "\n",
       "         water_prediction pos_prediction  \n",
       "1.0     Non_water_quality       Negative  \n",
       "2.0     Non_water_quality        Neutral  \n",
       "3.0     Non_water_quality        Neutral  \n",
       "4.0         Water_quality       Negative  \n",
       "5.0         Water_quality       Negative  \n",
       "...                   ...            ...  \n",
       "6805.0  Non_water_quality       Positive  \n",
       "6806.0  Non_water_quality       Positive  \n",
       "6807.0      Water_quality       Negative  \n",
       "6808.0      Water_quality       Negative  \n",
       "6809.0  Non_water_quality        Neutral  \n",
       "\n",
       "[6809 rows x 9 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
